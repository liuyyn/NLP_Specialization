# Coursera NLP Specialization Course 
**By Younes Bensouda and ≈Åukasz Kaiser**

### NLP with Classification and Vector Spaces
Use logistic regression, naive Bayes, and word vectors to implement
sentiment analysis, complete analogies, and translate words.

Assignments: Sentiment Analysis with Linear Regression, Naive Bayes, Word Analogies Prediction and Word
Embeddings, Naive Machine Translation and Locality-Sensitive Hashing.

### NLP with Probabilistic Models
Use dynamic programming, hidden Markov models, and word embeddings to
implement autocorrect, autocomplete, and identify part-of-speech tags for words.

Assignments: Auto-correct system, Part-of-Speech Tagging (POS), Auto-Complete system, Word Embeddings.

### NLP with Sequence Models
Use recurrent neural networks, LSTMs, GRUs and Siamese networks in TensorFlow
for sentiment analysis, text generation and named entity recognition.

Assignments: Sentiment with Deep Neural Networks, Deep N-grams, Named Entity Recognition, Questions
duplicates.

### NLP with Attention Models
Use encoder-decoder, causal, and self-attention to machine translate complete
sentences, summarize text, and answer questions.

Assignments: Neural Machine Translation, Transformer Summarizer, Question Answering.
